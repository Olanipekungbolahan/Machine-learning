{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59efaba3",
   "metadata": {},
   "source": [
    "### STEP 0: Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3559b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e1c51",
   "metadata": {},
   "source": [
    "### STEP 1: Read File as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e00950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.919</td>\n",
       "      <td>2.6909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.106</td>\n",
       "      <td>2.550</td>\n",
       "      <td>9.002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.932</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.949</td>\n",
       "      <td>1.591</td>\n",
       "      <td>0</td>\n",
       "      <td>7.253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.170</td>\n",
       "      <td>2.1144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.461</td>\n",
       "      <td>1.393</td>\n",
       "      <td>8.723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.214</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.315</td>\n",
       "      <td>1.967</td>\n",
       "      <td>0</td>\n",
       "      <td>7.257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.932</td>\n",
       "      <td>3.2512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.279</td>\n",
       "      <td>2.585</td>\n",
       "      <td>9.110</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009</td>\n",
       "      <td>1.152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.942</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.076</td>\n",
       "      <td>2.417</td>\n",
       "      <td>0</td>\n",
       "      <td>7.601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.7098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.100</td>\n",
       "      <td>0.918</td>\n",
       "      <td>6.594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.108</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.414</td>\n",
       "      <td>1.073</td>\n",
       "      <td>0</td>\n",
       "      <td>8.361</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.046</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.236</td>\n",
       "      <td>3.3944</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>3.449</td>\n",
       "      <td>2.753</td>\n",
       "      <td>9.528</td>\n",
       "      <td>2</td>\n",
       "      <td>1.004</td>\n",
       "      <td>1.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.985</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0</td>\n",
       "      <td>10.348</td>\n",
       "      <td>5.588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.351</td>\n",
       "      <td>2.405</td>\n",
       "      <td>0</td>\n",
       "      <td>8.003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1   2   3   4   5   6     7   8   9   10     11     12     13  \\\n",
       "0  3.919  2.6909   0   0   0   0   0  31.4   2   0   0  0.000  3.106  2.550   \n",
       "1  4.170  2.1144   0   0   0   0   0  30.8   1   1   0  0.000  2.461  1.393   \n",
       "2  3.932  3.2512   0   0   0   0   0  26.7   2   4   0  0.000  3.279  2.585   \n",
       "3  3.000  2.7098   0   0   0   0   0  20.0   0   2   0  0.000  2.100  0.918   \n",
       "4  4.236  3.3944   0   0   0   0   0  29.4   2   4   0 -0.271  3.449  2.753   \n",
       "\n",
       "      14  15     16     17  18  19  20     21  22  23  24  25     26     27  \\\n",
       "0  9.002   0  0.960  1.142   0   0   0  1.201   0   0   0   0  1.932  0.011   \n",
       "1  8.723   1  0.989  1.144   0   0   0  1.104   1   0   0   0  2.214 -0.204   \n",
       "2  9.110   0  1.009  1.152   0   0   0  1.092   0   0   0   0  1.942 -0.008   \n",
       "3  6.594   0  1.108  1.167   0   0   0  1.024   0   0   0   0  1.414  1.073   \n",
       "4  9.528   2  1.004  1.147   0   0   0  1.137   0   0   0   0  1.985 -0.002   \n",
       "\n",
       "   28      29     30  31  32  33  34     35     36  37     38  39  40  41  \n",
       "0   0   0.000  4.489   0   0   0   0  2.949  1.591   0  7.253   0   0   1  \n",
       "1   0   0.000  1.542   0   0   0   0  3.315  1.967   0  7.257   0   0   1  \n",
       "2   0   0.000  4.891   0   0   0   1  3.076  2.417   0  7.601   0   0   1  \n",
       "3   0   8.361  1.333   0   0   0   1  3.046  5.000   0  6.690   0   0   1  \n",
       "4   0  10.348  5.588   0   0   0   0  3.351  2.405   0  8.003   0   0   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data then Display first 5 rows\n",
    "data=pd.read_csv(\"biodeg.csv\",header=None) #read CSV files\n",
    "pd.set_option('display.max_columns', None) #format data frame to show all columns\n",
    "data.head() #display first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c574f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.782644</td>\n",
       "      <td>3.069508</td>\n",
       "      <td>0.716588</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>0.980095</td>\n",
       "      <td>0.290047</td>\n",
       "      <td>1.646445</td>\n",
       "      <td>37.055640</td>\n",
       "      <td>1.376303</td>\n",
       "      <td>1.803791</td>\n",
       "      <td>1.436967</td>\n",
       "      <td>-0.197129</td>\n",
       "      <td>3.476844</td>\n",
       "      <td>1.350716</td>\n",
       "      <td>9.937381</td>\n",
       "      <td>3.630332</td>\n",
       "      <td>1.013302</td>\n",
       "      <td>1.131106</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.073934</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>1.238727</td>\n",
       "      <td>1.405687</td>\n",
       "      <td>0.039810</td>\n",
       "      <td>0.147867</td>\n",
       "      <td>0.031280</td>\n",
       "      <td>2.215641</td>\n",
       "      <td>-0.001206</td>\n",
       "      <td>0.026540</td>\n",
       "      <td>8.780510</td>\n",
       "      <td>2.668344</td>\n",
       "      <td>0.129858</td>\n",
       "      <td>0.883412</td>\n",
       "      <td>1.274882</td>\n",
       "      <td>0.961137</td>\n",
       "      <td>3.918240</td>\n",
       "      <td>2.558417</td>\n",
       "      <td>0.686256</td>\n",
       "      <td>8.629492</td>\n",
       "      <td>0.051185</td>\n",
       "      <td>0.723223</td>\n",
       "      <td>0.337441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.546916</td>\n",
       "      <td>0.831308</td>\n",
       "      <td>1.462452</td>\n",
       "      <td>0.256010</td>\n",
       "      <td>2.332955</td>\n",
       "      <td>1.073771</td>\n",
       "      <td>2.224822</td>\n",
       "      <td>9.144466</td>\n",
       "      <td>1.963521</td>\n",
       "      <td>1.775435</td>\n",
       "      <td>3.116577</td>\n",
       "      <td>0.769662</td>\n",
       "      <td>0.584150</td>\n",
       "      <td>0.786166</td>\n",
       "      <td>0.928678</td>\n",
       "      <td>4.457243</td>\n",
       "      <td>0.046494</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>0.101802</td>\n",
       "      <td>0.317475</td>\n",
       "      <td>0.217997</td>\n",
       "      <td>0.096466</td>\n",
       "      <td>4.788542</td>\n",
       "      <td>0.195606</td>\n",
       "      <td>0.355137</td>\n",
       "      <td>0.199544</td>\n",
       "      <td>0.226131</td>\n",
       "      <td>0.158928</td>\n",
       "      <td>0.160812</td>\n",
       "      <td>11.895889</td>\n",
       "      <td>2.096607</td>\n",
       "      <td>0.644057</td>\n",
       "      <td>1.520467</td>\n",
       "      <td>2.273994</td>\n",
       "      <td>1.257013</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.642765</td>\n",
       "      <td>1.090389</td>\n",
       "      <td>1.241986</td>\n",
       "      <td>0.318970</td>\n",
       "      <td>2.239286</td>\n",
       "      <td>0.473061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.803900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.256000</td>\n",
       "      <td>1.544000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.174000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957000</td>\n",
       "      <td>1.022000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.099000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.267000</td>\n",
       "      <td>1.467000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.917000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.481000</td>\n",
       "      <td>2.502750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.191000</td>\n",
       "      <td>3.105000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>9.533000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>1.116000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.182000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.101000</td>\n",
       "      <td>-0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.446500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.487500</td>\n",
       "      <td>2.103000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.991000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.828000</td>\n",
       "      <td>3.046300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.442000</td>\n",
       "      <td>1.187000</td>\n",
       "      <td>10.039000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.003000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.243000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.247000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.726000</td>\n",
       "      <td>2.458000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.499000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.125000</td>\n",
       "      <td>3.437650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>43.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.825500</td>\n",
       "      <td>1.705000</td>\n",
       "      <td>10.514500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.029000</td>\n",
       "      <td>1.143000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.296000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.358000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.465000</td>\n",
       "      <td>3.146000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.987000</td>\n",
       "      <td>2.870500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.020500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.496000</td>\n",
       "      <td>9.177500</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>60.700000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4.722000</td>\n",
       "      <td>5.701000</td>\n",
       "      <td>4.491000</td>\n",
       "      <td>12.609000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.311000</td>\n",
       "      <td>1.377000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.641000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.859000</td>\n",
       "      <td>1.073000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.167000</td>\n",
       "      <td>17.537000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.695000</td>\n",
       "      <td>5.825000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1055.000000  1055.000000  1055.000000  1055.000000  1055.000000   \n",
       "mean      4.782644     3.069508     0.716588     0.042654     0.980095   \n",
       "std       0.546916     0.831308     1.462452     0.256010     2.332955   \n",
       "min       2.000000     0.803900     0.000000     0.000000     0.000000   \n",
       "25%       4.481000     2.502750     0.000000     0.000000     0.000000   \n",
       "50%       4.828000     3.046300     0.000000     0.000000     0.000000   \n",
       "75%       5.125000     3.437650     1.000000     0.000000     1.000000   \n",
       "max       6.496000     9.177500    12.000000     3.000000    36.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  1055.000000  1055.000000  1055.000000  1055.000000  1055.000000   \n",
       "mean      0.290047     1.646445    37.055640     1.376303     1.803791   \n",
       "std       1.073771     2.224822     9.144466     1.963521     1.775435   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000    30.450000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000    37.500000     1.000000     2.000000   \n",
       "75%       0.000000     3.000000    43.400000     2.000000     3.000000   \n",
       "max      13.000000    18.000000    60.700000    24.000000    12.000000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  1055.000000  1055.000000  1055.000000  1055.000000  1055.000000   \n",
       "mean      1.436967    -0.197129     3.476844     1.350716     9.937381   \n",
       "std       3.116577     0.769662     0.584150     0.786166     0.928678   \n",
       "min       0.000000    -5.256000     1.544000     0.000000     4.174000   \n",
       "25%       0.000000    -0.191000     3.105000     0.875000     9.533000   \n",
       "50%       0.000000     0.000000     3.442000     1.187000    10.039000   \n",
       "75%       2.000000     0.000000     3.825500     1.705000    10.514500   \n",
       "max      44.000000     4.722000     5.701000     4.491000    12.609000   \n",
       "\n",
       "                15           16           17           18           19  \\\n",
       "count  1055.000000  1055.000000  1055.000000  1055.000000  1055.000000   \n",
       "mean      3.630332     1.013302     1.131106     0.008531     0.073934   \n",
       "std       4.457243     0.046494     0.030143     0.101802     0.317475   \n",
       "min       0.000000     0.957000     1.022000     0.000000     0.000000   \n",
       "25%       0.000000     0.983000     1.116000     0.000000     0.000000   \n",
       "50%       2.000000     1.003000     1.130000     0.000000     0.000000   \n",
       "75%       6.000000     1.029000     1.143000     0.000000     0.000000   \n",
       "max      40.000000     1.311000     1.377000     2.000000     3.000000   \n",
       "\n",
       "                20           21           22           23           24  \\\n",
       "count  1055.000000  1055.000000  1055.000000  1055.000000  1055.000000   \n",
       "mean      0.029384     1.238727     1.405687     0.039810     0.147867   \n",
       "std       0.217997     0.096466     4.788542     0.195606     0.355137   \n",
       "min       0.000000     0.863000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.182000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.243000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.296000     2.000000     0.000000     0.000000   \n",
       "max       3.000000     1.641000   147.000000     1.000000     1.000000   \n",
       "\n",
       "                25           26           27           28           29  \\\n",
       "count  1055.000000  1055.000000  1055.000000  1055.000000  1055.000000   \n",
       "mean      0.031280     2.215641    -0.001206     0.026540     8.780510   \n",
       "std       0.199544     0.226131     0.158928     0.160812    11.895889   \n",
       "min       0.000000     1.000000    -1.099000     0.000000     0.000000   \n",
       "25%       0.000000     2.101000    -0.008000     0.000000     0.000000   \n",
       "50%       0.000000     2.247000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     2.358000     0.005000     0.000000    12.465000   \n",
       "max       3.000000     2.859000     1.073000     1.000000    71.167000   \n",
       "\n",
       "                30           31           32           33           34  \\\n",
       "count  1055.000000  1055.000000  1055.000000  1055.000000  1055.000000   \n",
       "mean      2.668344     0.129858     0.883412     1.274882     0.961137   \n",
       "std       2.096607     0.644057     1.520467     2.273994     1.257013   \n",
       "min       0.444000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.446500     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       2.052000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       3.146000     0.000000     1.000000     2.000000     2.000000   \n",
       "max      17.537000     8.000000    12.000000    18.000000     7.000000   \n",
       "\n",
       "                35           36           37           38           39  \\\n",
       "count  1055.000000  1055.000000  1055.000000  1055.000000  1055.000000   \n",
       "mean      3.918240     2.558417     0.686256     8.629492     0.051185   \n",
       "std       0.999602     0.642765     1.090389     1.241986     0.318970   \n",
       "min       2.267000     1.467000     0.000000     4.917000     0.000000   \n",
       "25%       3.487500     2.103000     0.000000     7.991000     0.000000   \n",
       "50%       3.726000     2.458000     0.000000     8.499000     0.000000   \n",
       "75%       3.987000     2.870500     1.000000     9.020500     0.000000   \n",
       "max      10.695000     5.825000     8.000000    14.700000     4.000000   \n",
       "\n",
       "                40           41  \n",
       "count  1055.000000  1055.000000  \n",
       "mean      0.723223     0.337441  \n",
       "std       2.239286     0.473061  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.000000     0.000000  \n",
       "50%       0.000000     0.000000  \n",
       "75%       0.000000     1.000000  \n",
       "max      27.000000     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data to see \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dddba6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1055 entries, 0 to 1054\n",
      "Data columns (total 42 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1055 non-null   float64\n",
      " 1   1       1055 non-null   float64\n",
      " 2   2       1055 non-null   int64  \n",
      " 3   3       1055 non-null   int64  \n",
      " 4   4       1055 non-null   int64  \n",
      " 5   5       1055 non-null   int64  \n",
      " 6   6       1055 non-null   int64  \n",
      " 7   7       1055 non-null   float64\n",
      " 8   8       1055 non-null   int64  \n",
      " 9   9       1055 non-null   int64  \n",
      " 10  10      1055 non-null   int64  \n",
      " 11  11      1055 non-null   float64\n",
      " 12  12      1055 non-null   float64\n",
      " 13  13      1055 non-null   float64\n",
      " 14  14      1055 non-null   float64\n",
      " 15  15      1055 non-null   int64  \n",
      " 16  16      1055 non-null   float64\n",
      " 17  17      1055 non-null   float64\n",
      " 18  18      1055 non-null   int64  \n",
      " 19  19      1055 non-null   int64  \n",
      " 20  20      1055 non-null   int64  \n",
      " 21  21      1055 non-null   float64\n",
      " 22  22      1055 non-null   int64  \n",
      " 23  23      1055 non-null   int64  \n",
      " 24  24      1055 non-null   int64  \n",
      " 25  25      1055 non-null   int64  \n",
      " 26  26      1055 non-null   float64\n",
      " 27  27      1055 non-null   float64\n",
      " 28  28      1055 non-null   int64  \n",
      " 29  29      1055 non-null   float64\n",
      " 30  30      1055 non-null   float64\n",
      " 31  31      1055 non-null   int64  \n",
      " 32  32      1055 non-null   int64  \n",
      " 33  33      1055 non-null   int64  \n",
      " 34  34      1055 non-null   int64  \n",
      " 35  35      1055 non-null   float64\n",
      " 36  36      1055 non-null   float64\n",
      " 37  37      1055 non-null   int64  \n",
      " 38  38      1055 non-null   float64\n",
      " 39  39      1055 non-null   int64  \n",
      " 40  40      1055 non-null   int64  \n",
      " 41  41      1055 non-null   int64  \n",
      "dtypes: float64(17), int64(25)\n",
      "memory usage: 346.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee79400f",
   "metadata": {},
   "source": [
    "**No missing values and all variables are numeric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03495031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the number of 1's and 0's\n",
    "sns.countplot(x=41,data=data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba4857",
   "metadata": {},
   "source": [
    "**NB: There is a class imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897d8464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of 1's:356\n",
      "No of 0's:699\n"
     ]
    }
   ],
   "source": [
    "# Count the no of 1's and 0's\n",
    "print(\"No of 1's:{}\".format(data.iloc[:,-1][data.iloc[:,-1]==1].count()))\n",
    "print(\"No of 0's:{}\".format(data.iloc[:,-1][data.iloc[:,-1]==0].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20cdc03",
   "metadata": {},
   "source": [
    "**NB: Though there is a class, decision to resample will not be taken since the minority class still meets up to more than half of majority class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044ce418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into predictor and targets\n",
    "y = data.iloc[:,-1]\n",
    "X = data.drop(41,axis=1)\n",
    "labels=list(X.columns)\n",
    "number_features = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df720550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data to test and train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdab31e",
   "metadata": {},
   "source": [
    "### STEP 2: Train a classifier.\n",
    "#### A. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b21573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 80 candidates, totalling 320 fits\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10}\n",
      "Accuracy_Train: 0.8794037940379403\n",
      " Accuracy_Test: 0.8454258675078864\n",
      "\n",
      " Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       224\n",
      "           1       0.71      0.80      0.75        93\n",
      "\n",
      "    accuracy                           0.85       317\n",
      "   macro avg       0.81      0.83      0.82       317\n",
      "weighted avg       0.85      0.85      0.85       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialise decision Tree Model\n",
    "decision_model = DecisionTreeClassifier(random_state=15)\n",
    "\n",
    "# Use Grid Search to get an array of Parameters \n",
    "params = {\n",
    "    'max_depth': [2,3, 4, 5, 8,10,15, 20],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "decision = GridSearchCV(decision_model,\n",
    "                        param_grid=params, \n",
    "                        cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
    "\n",
    "# Train Decision Tree Model\n",
    "start_time = time.time()\n",
    "decision.fit(X_train, y_train) # fit model\n",
    "decision_time = time.time() - start_time\n",
    "print(\"Best Parameters:\",decision.best_params_)\n",
    "print('Accuracy_Train: {}\\n Accuracy_Test: {}\\n\\n Report:\\n  {}'.format(decision.score(X_train, y_train),\n",
    "      decision.score(X_test, y_test),classification_report(y_test,decision.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bd2740",
   "metadata": {},
   "source": [
    "#### B. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e99fa0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Train: 0.8035230352303523\n",
      " Accuracy_Test: 0.7602523659305994\n",
      "\n",
      " Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82       224\n",
      "           1       0.57      0.76      0.65        93\n",
      "\n",
      "    accuracy                           0.76       317\n",
      "   macro avg       0.73      0.76      0.73       317\n",
      "weighted avg       0.79      0.76      0.77       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "naive_bayes= BernoulliNB()\n",
    "\n",
    "start_time = time.time()\n",
    "naive_bayes.fit(X_train, y_train) \n",
    "bayes_time = time.time() - start_time\n",
    "print('Accuracy_Train: {}\\n Accuracy_Test: {}\\n\\n Report:\\n  {}'.format(naive_bayes.score(X_train, y_train),\n",
    "      naive_bayes.score(X_test, y_test),classification_report(y_test,naive_bayes.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535cde6",
   "metadata": {},
   "source": [
    "#### C. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c96ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 'relu', 'alpha': 0.05, 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Accuracy_Train: 0.9132791327913279\n",
      " Accuracy_Test: 0.8485804416403786\n",
      "\n",
      " Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       224\n",
      "           1       0.79      0.66      0.72        93\n",
      "\n",
      "    accuracy                           0.85       317\n",
      "   macro avg       0.83      0.79      0.81       317\n",
      "weighted avg       0.84      0.85      0.84       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Initialise neural network\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(50,50,50),max_iter=1000)\n",
    "\n",
    "parameter_space={'activation':['tanh','relu'],\n",
    "                 'solver':['lbfgs','sgd','adam'],\n",
    "                 'alpha':[0.0001,0.05],\n",
    "                 'learning_rate':['constant','adaptive','invscaling']\n",
    "                }\n",
    "\n",
    "# Use grid search to tune\n",
    "mlp_clf=GridSearchCV(mlp,parameter_space,n_jobs=-1,cv=5)\n",
    "\n",
    "# Train model\n",
    "start_time = time.time()\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "mlp_time = time.time() - start_time\n",
    "\n",
    "print(\"Best Parameters:\",mlp_clf.best_params_)\n",
    "print('Accuracy_Train: {}\\n Accuracy_Test: {}\\n\\n Report:\\n  {}'.format(mlp_clf.score(X_train, y_train),\n",
    "      mlp_clf.score(X_test, y_test),classification_report(y_test,mlp_clf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cc132",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec2c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Train: 0.997289972899729\n",
      " Accuracy_Test: 0.8643533123028391\n",
      "\n",
      " Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       224\n",
      "           1       0.76      0.80      0.77        93\n",
      "\n",
      "    accuracy                           0.86       317\n",
      "   macro avg       0.83      0.84      0.84       317\n",
      "weighted avg       0.87      0.86      0.87       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_model = RandomForestClassifier()\n",
    "params={'n_estimators':[100, 200, 400, 800, 1200],\n",
    "        'max_depth':[5, 10, 15, 25, 30]} \n",
    "\n",
    "forest=GridSearchCV(forest_model,params,n_jobs=-1,cv=5)\n",
    "\n",
    "start_time = time.time()\n",
    "forest.fit(X_train, y_train) # fit model\n",
    "forest_time=time.time() - start_time\n",
    "\n",
    "# \n",
    "print('Accuracy_Train: {}\\n Accuracy_Test: {}\\n\\n Report:\\n  {}'.format(forest.score(X_train, y_train),\n",
    "      forest.score(X_test, y_test),classification_report(y_test,forest.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc2a95",
   "metadata": {},
   "source": [
    "### STEP 3: Record your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740f7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={'Accuracy (train)':[],'Accuracy (validation)':[],\n",
    "         'Training Time':[decision_time,bayes_time,mlp_time,forest_time],\n",
    "         'model':['Decision tree','Naive Bayes Classifier','Neural network','Random forest']}\n",
    "\n",
    "ind=[decision,naive_bayes,mlp_clf,forest]\n",
    "\n",
    "for i in  range(len(ind)):\n",
    "  results['Accuracy (train)'].append(ind[i].score(X_train, y_train))\n",
    "  results['Accuracy (validation)'].append(ind[i].score(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0573cb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (train)</th>\n",
       "      <th>Accuracy (validation)</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision tree</th>\n",
       "      <td>0.879404</td>\n",
       "      <td>0.845426</td>\n",
       "      <td>4.121078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes Classifier</th>\n",
       "      <td>0.803523</td>\n",
       "      <td>0.760252</td>\n",
       "      <td>0.002692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural network</th>\n",
       "      <td>0.913279</td>\n",
       "      <td>0.848580</td>\n",
       "      <td>141.262120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.997290</td>\n",
       "      <td>0.864353</td>\n",
       "      <td>33.339999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy (train)  Accuracy (validation)  Training Time\n",
       "model                                                                         \n",
       "Decision tree                   0.879404               0.845426       4.121078\n",
       "Naive Bayes Classifier          0.803523               0.760252       0.002692\n",
       "Neural network                  0.913279               0.848580     141.262120\n",
       "Random forest                   0.997290               0.864353      33.339999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results).set_index('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a9864",
   "metadata": {},
   "source": [
    "### STEP 4: Make your method replicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d582fccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10}\n",
      "\n",
      "Naive Bayes Classifier: BernoulliNB with default sklearn parameter\n",
      "\n",
      "Neural network: {'activation': 'relu', 'alpha': 0.05, 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "\n",
      "Random forest:Default Parameters \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Decision tree: {}\\n\\nNaive Bayes Classifier: {}\\n\\nNeural network: {}\\n\\nRandom forest:{} \\n'\n",
    "      .format(decision.best_params_,'BernoulliNB with default sklearn parameter',mlp_clf.best_params_,'Default Parameters'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
